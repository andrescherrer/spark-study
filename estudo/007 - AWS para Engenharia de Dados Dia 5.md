# AWS CloudWatch + Troubleshooting: Guia Especializado

Como especialista com 20 anos na √°rea, vou estruturar isso de forma progressiva, come√ßando pelos fundamentos at√© casos reais complexos.

---

## üìä 1. LOGS, M√âTRICAS E ALARMES (2h)

### O que √© CloudWatch?

CloudWatch √© o sistema nervoso da AWS. Funciona como um agregador centralizado de **observabilidade** - coleta tudo que acontece na sua infraestrutura (EC2, RDS, Lambda, etc) e te permite investigar quando algo d√° errado.

**Componentes fundamentais:**

**Logs** s√£o registros textuais de eventos. Imagine que cada aplica√ß√£o grita "ei, algo aconteceu aqui!" e CloudWatch escuta. Diferente de m√©tricas num√©ricas, logs cont√™m contexto completo - stack traces, queries SQL lentas, erros de autentica√ß√£o.

**M√©tricas** s√£o valores num√©ricos pontuais no tempo. CPU em 78%, mem√≥ria em 2.1GB, requisi√ß√µes processadas em 150/segundo. S√£o agregadas em per√≠odos (1min, 5min, 1h).

**Alarmes** s√£o regras que voc√™ define: "se CPU > 80% por mais de 5 minutos, envie um SNS (notifica√ß√£o)". S√£o a√ß√µes autom√°ticas baseadas em limites.

### Documenta√ß√£o oficial para estudar:
- **CloudWatch Overview**: https://docs.aws.amazon.com/cloudwatch/
- **Logs Insights (query language)**: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html
- **M√©tricas padr√£o**: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html

### Exemplo pr√°tico - Engenharia de Dados:

```
Cen√°rio: ETL pipeline em Lambda processa 10GB de dados diariamente

Logs que voc√™ v√™ no CloudWatch:
[ERROR] S3 object key not found: s3://data-lake/inputs/2025-10-20/sales.parquet
[WARN] Row count mismatch: expected 1,000,000 rows, got 999,855
[INFO] Data transformation completed in 312 seconds

M√©tricas correlacionadas:
- Duration: 312 segundos (aumentou 50% vs ontem)
- Memory Used: 2,150 MB (quase no limite de 3GB)
- Errors: 3 (vs 0 ontem)

Alarme disparado: "Lambda duration > 300s para 3 execu√ß√µes consecutivas"
```

---

## üìà 2. DASHBOARD CUSTOMIZADO (2h)

Um dashboard √© sua "sala de controle". Em vez de clicar em 15 abas diferentes, voc√™ v√™ tudo de uma vez.

### Por que √© cr√≠tico em Engenharia de Dados:

Em pipelines complexos, voc√™ precisa monitorar **simultaneamente**:
- Performance do pipeline (quanto tempo levou?)
- Qualidade dos dados (quantas linhas processadas?)
- Custos (quanto gastei neste job?)
- Sa√∫de da infraestrutura (RDS CPU, disco dispon√≠vel)

### Documenta√ß√£o:
- **Creating Dashboards**: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards.html
- **Dashboard widgets**: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards_Widgets.html

### Exemplo pr√°tico - Dashboard de Data Pipeline:

Imagine um dashboard com 6 widgets:

**Widget 1: Timeline de execu√ß√£o do pipeline**
```
16:00 - Extra√ß√£o de dados (5 min) ‚úì
16:05 - Transforma√ß√£o (45 min) ‚úì
16:50 - Carga para Data Warehouse (12 min) ‚úì
17:02 - Valida√ß√£o de qualidade (2 min) ‚úì
```
(M√©trica: Duration do Step Functions)

**Widget 2: Evolu√ß√£o de registros processados**
```
Gr√°fico em linha:
- Dia 18: 1,200,000 registros
- Dia 19: 1,185,000 registros ‚ö†Ô∏è (queda de 1.2%)
- Dia 20: 890,000 registros üî¥ (queda de 25%)
```
(M√©trica customizada: Row count enviada por Lambda)

**Widget 3: Taxa de erro**
```
Erros por tipo:
- Schema mismatch: 2
- Missing values: 15
- Duplicates: 0
```

**Widget 4: Custo acumulado**
```
Hoje: $12.50 (Lambda + S3 + RDS)
Essa semana: $84.30
M√™s: $1,240
```

**Widget 5: Sa√∫de da RDS**
```
CPU: 45% | Mem√≥ria: 62% | Conex√µes: 28/100 | IOPS: 180/1000
```

**Widget 6: Alertas ativos**
```
‚ö†Ô∏è Lambda timeout em 2 execu√ß√µes
üî¥ RDS disk space 78% utilizado
```

---

## üí∞ 3. ENTENDER CUSTOS (2h)

Este √© o ponto mais **subestimado** e mais **caro** de se ignorar.

### Como CloudWatch cobra:

1. **M√©tricas**: $0.30 por m√©trica customizada/m√™s (as default EC2 s√£o gr√°tis)
2. **Logs**: $0.50 por GB ingerido + $0.03 por GB armazenado/m√™s
3. **API calls**: Gr√°tis (at√© um ponto, ent√£o n√£o √© relevante)
4. **Dashboards**: Gr√°tis

**O verdadeiro custo est√° nos LOGS.**

### Documenta√ß√£o de custos:
- **CloudWatch Pricing**: https://aws.amazon.com/cloudwatch/pricing/

### Cen√°rio real - Voc√™ est√° vazando dinheiro:

Uma equipe de engenharia de dados tem um Lambda que:
- Executa 100 vezes/dia
- Loga 50MB de output por execu√ß√£o (DEBUG level ativo por engano)

```
C√°lculo:
100 execu√ß√µes √ó 50MB = 5GB/dia
5GB/dia √ó 30 dias = 150GB/m√™s
150GB √ó $0.50 = $75/m√™s EM LOGS APENAS
(Sem contar reten√ß√£o)
```

**Se voc√™ guardar esses logs por 1 ano:**
```
150GB √ó 12 meses √ó $0.03 = $54/ano EM ARMAZENAMENTO
```

**Solu√ß√£o implementada (reduz custos 95%):**
- Logs DEBUG v√£o para S3 (apenas se erro ocorrer)
- CloudWatch recebe apenas INFO/ERROR (2MB/execu√ß√£o)
- 2GB/dia √ó 30 = 60GB/m√™s √ó $0.50 = $30/m√™s

**Economia: $45/m√™s = $540/ano**

### Documenta√ß√£o avan√ßada de otimiza√ß√£o:
- **Log Insights pricing**: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CloudWatch-Logs-Insights-Pricing.html

---

## üîß 4. TROUBLESHOOTING PR√ÅTICO (2h)

Aqui √© onde a experi√™ncia faz diferen√ßa.

### Documenta√ß√£o refer√™ncia:
- **Monitoring AWS services**: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Best_Practice_Recommended_Alarms_AWS_Services.html
- **Troubleshooting guide**: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Troubleshooting.html

### Fluxo de diagn√≥stico que uso:

**1. O que est√° errado? (Identify)**
- Verifique Alarms na console
- Procure por m√©tricas anormais no dashboard

**2. Quando come√ßou? (Timeline)**
- CloudWatch Insights: `fields @timestamp, @message | sort @timestamp desc | limit 100`
- Correlacione com mudan√ßas recentes (deployment, altera√ß√£o de schema, pico de tr√°fego)

**3. Quem/O qu√™ foi afetado? (Scope)**
- A todo o pipeline ou apenas uma etapa?
- Um usu√°rio espec√≠fico ou todos?

**4. Por que aconteceu? (Root Cause)**
- Verifique aplica√ß√£o + infraestrutura + dados

---

## üåç EXEMPLOS DO MUNDO REAL - Engenharia de Dados

### Caso 1: Pipeline de ETL parou de produzir dados

**Sintomas:**
- Alarme: "Data Warehouse n√£o recebeu nova carga em 4 horas"
- Dashboard mostra: √öltima execu√ß√£o bem-sucedida foi ontem 14:00

**Investiga√ß√£o com CloudWatch:**

```sql
-- Query no Logs Insights
fields @timestamp, @message, @duration
| filter @message like /ERROR|FAILED/
| stats count() as error_count by bin(5m)
```

**Descoberta:** √Äs 10:15 come√ßaram erros de timeout em query SQL:

```
[ERROR] Query timeout after 300 seconds
SELECT COUNT(*) FROM raw_data WHERE date = '2025-10-20'
```

**Causa raiz:** A tabela `raw_data` cresceu de 2B para 5B de linhas (sem √≠ndice)

**Solu√ß√£o:** Criar √≠ndice em `date` column

```sql
CREATE INDEX idx_raw_data_date ON raw_data(date);
```

**M√©trica ap√≥s fix:** Tempo de query caiu de 320s para 2s

---

### Caso 2: Custos dispararam 400%

**Descoberta:** CloudWatch mostrava 800GB de logs/m√™s (vs 50GB m√™s anterior)

**Investiga√ß√£o:**

```sql
-- Descobrir qual servi√ßo consome mais logs
fields @logStream
| stats sum(strtonum(@message)) as log_size by @logStream
| sort log_size desc
| limit 10
```

**Resultado:** Lambda que faz data processing estava logando TUDO (Arrays gigantes de dados brutos)

**C√≥digo problem√°tico:**
```php
// RUIM - Loga array inteiro
logger->info("Processing data", ['raw_data' => $dataArray]);

// BOM - Loga apenas metadata
logger->info("Processing data", [
    'row_count' => count($dataArray),
    'processing_time_ms' => $elapsed,
    'status' => 'success'
]);
```

---

### Caso 3: Qualidade de dados piora progressivamente

**Observa√ß√£o:** Dashboard mostra m√©trica customizada "duplicate_records" subindo:

```
Dia 18: 10 duplicatas (0.001%)
Dia 19: 150 duplicatas (0.013%)
Dia 20: 2.100 duplicatas (0.2%)
```

**Investiga√ß√£o:** Verifique logs de transforma√ß√£o

```sql
fields @timestamp, transform_step, @message
| filter transform_step like /deduplication/
| stats count() as errors by @message
```

**Descoberta:** Falha silenciosa na deduplica√ß√£o ap√≥s mudan√ßa no schema de dados

**Causa:** Novo campo adicionado √† source que quebrou l√≥gica de hash

**Solu√ß√£o:** Atualizar fun√ß√£o de deduplica√ß√£o para incluir novo campo

---

## üìö Resumo de Documenta√ß√£o Essencial

| T√≥pico | Link |
|--------|------|
| CloudWatch Core | https://docs.aws.amazon.com/cloudwatch/ |
| Logs Insights Query | https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html |
| M√©tricas Customizadas | https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html |
| Alarmes | https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html |
| Dashboards | https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Dashboards.html |
| Pricing | https://aws.amazon.com/cloudwatch/pricing/ |
| Best Practices | https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Best_Practice_Recommended_Alarms_AWS_Services.html |

---

## üí° Conselho Final

O verdadeiro valor do CloudWatch n√£o est√° em ver tudo em tempo real, mas em ter dados suficientes para fazer perguntas inteligentes quando algo quebra. Estruture seus logs para serem "query√°veis" - pense em campos estruturados, n√£o em strings livres.